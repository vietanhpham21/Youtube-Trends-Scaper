{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb688672",
   "metadata": {},
   "source": [
    "Skript zum Scrapen der YT-Trends\n",
    "\n",
    "Beispiel eines Datensatzes:\n",
    "\n",
    "    \"rank\": \"#1\",\n",
    "    \"channel\": \"DAVE\",\n",
    "    \"subs\": \"1,16 Mio.\",\n",
    "    \"title\": \"THE RACE - Die erste Nacht bricht an - Folge 03\",\n",
    "    \"views\": \"612.386\",\n",
    "    \"likes\": \"38613\",\n",
    "    \"dislikes\": \"457\",\n",
    "    \"comments\": \"1.474\",\n",
    "    \"publication_date\": \"07.07.2024\",\n",
    "    \"description\": ---\n",
    "    \"video_url\": \"https://www.youtube.com/watch?v=iVXllgfjmeQ\",\n",
    "    \"channel_url\": \"https://www.youtube.com/@dave_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4148774d-9e64-4b29-ab72-d58000b6c496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver \n",
    "import pandas as pd \n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common import TimeoutException, StaleElementReferenceException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from utils import extract_likes\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "from tqdm import tqdm  # Import tqdm for progress bar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8fd074",
   "metadata": {},
   "source": [
    "Funktion zum Speichern der Daten in eine JSON-Datei mit einem Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3af110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_videos_with_timestamp(videos, output_dir):\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M')\n",
    "    filename = f'trends_tracking_{timestamp}.json'\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    \n",
    "    try:\n",
    "        # Erstelle ein Objekt mit allen Videos und einem gemeinsamen scraped_at\n",
    "        data = {\n",
    "            'scraped_at': timestamp,\n",
    "            'videos': videos\n",
    "        }\n",
    "\n",
    "        with open(filepath, 'w', encoding='utf-8') as file:\n",
    "            json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "            print(f'Data saved to {filepath}')\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving {filename}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6325c8af",
   "metadata": {},
   "source": [
    "Initialisierung des Webdrivers und navigiere zur Trends Seite\n",
    "\n",
    "Es müssen zuerst die Cookies akzeptiert werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bb8a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "# Addon das Dislike Anzahl anzeigt\n",
    "chrome_options.add_extension('./add_dislike_addon.crx')\n",
    "# macht Browser unsichtbar\n",
    "# chrome_options.add_argument('--headless=new')\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)  \n",
    "driver.get('https://www.youtube.com/feed/trending')\n",
    "\n",
    "try:\n",
    "\n",
    "    accept_all = driver.find_element(By.XPATH, '/html/body/c-wiz/div/div/div/div[2]/div[1]/div[3]/div[1]/form[2]/div/div/button')\n",
    "\n",
    "    accept_all.click()\n",
    "except TimeoutException:\n",
    "    print('Cookie Modal not found')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b93a01c",
   "metadata": {},
   "source": [
    "Logik zum scrapen der Information des jeweiligen Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681a6599-517e-4d05-b2c8-13109ec6932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_video_data(driver, rank, video_link):\n",
    "    try:\n",
    "        WebDriverWait(driver, 30).until(\n",
    "            EC.visibility_of_element_located((By.CSS_SELECTOR, 'h1.ytd-watch-metadata'))\n",
    "        )\n",
    "\n",
    "        video = {}\n",
    "        # Channel Informationen\n",
    "        channel_element = driver.find_element(By.ID, 'owner')\n",
    "        channel_url = channel_element.find_element(By.CSS_SELECTOR, 'a.yt-simple-endpoint').get_attribute('href')\n",
    "        channel = channel_element.find_element(By.ID, 'channel-name').text\n",
    "        subs = channel_element.find_element(By.ID, 'owner-sub-count').text.replace(' Abonnenten', '')\n",
    "\n",
    "        # Öffnet die Beschreibung\n",
    "        time.sleep(1)\n",
    "        driver.find_element(By.CSS_SELECTOR, '#description-inline-expander #expand').click()\n",
    "\n",
    "        # Video Informationen\n",
    "        title = driver.find_element(By.CSS_SELECTOR, 'h1.ytd-watch-metadata').text\n",
    "\n",
    "        info_container_elements = driver.find_elements(By.CSS_SELECTOR, '#info-container span')\n",
    "        views = info_container_elements[0].text.replace(' Aufrufe', '')\n",
    "        publication_date = info_container_elements[2].text\n",
    "        description = driver.find_element(By.CSS_SELECTOR, '#description-inline-expander .ytd-text-inline-expander span').text\n",
    "\n",
    "        like_button = driver.find_element(By.CSS_SELECTOR, '[aria-label*=\"Ich mag das Video\"]')\n",
    "        aria_label_text = like_button.get_attribute('aria-label')\n",
    "        likes = extract_likes(aria_label_text)\n",
    "        \n",
    "        dislikes = driver.find_element(By.CSS_SELECTOR, '.YtDislikeButtonViewModelHost button').text\n",
    "\n",
    "        # Scrolle um Kommentare zu laden\n",
    "        body = driver.find_element(By.TAG_NAME, 'body')\n",
    "        for _ in range(7):\n",
    "            body.send_keys(Keys.PAGE_DOWN)\n",
    "            \n",
    "        WebDriverWait(driver, 30).until(\n",
    "            EC.visibility_of_element_located((By.CSS_SELECTOR, '#comments ytd-comments-header-renderer span'))\n",
    "        )\n",
    "        num_comments = driver.find_elements(By.CSS_SELECTOR, '#comments ytd-comments-header-renderer span')[0].text\n",
    "\n",
    "        video['rank'] = f'#{rank}'\n",
    "        video['channel'] = channel\n",
    "        video['subs'] = subs\n",
    "        video['title'] = title\n",
    "        video['views'] = views\n",
    "        video['likes'] = likes\n",
    "        video['dislikes'] = dislikes\n",
    "        video['comments'] = num_comments\n",
    "        video['publication_date'] = publication_date\n",
    "        video['description'] = description\n",
    "        video['video_url'] = video_link\n",
    "        video['channel_url'] = channel_url\n",
    "        \n",
    "\n",
    "        return video\n",
    "\n",
    "    except Exception as e:\n",
    "        raise Exception({str(e)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7976c1b2",
   "metadata": {},
   "source": [
    "Hole alle Video-Links auf der Seite und scrape für jedes Video die Infos.\n",
    "\n",
    "\n",
    "Speichern der Daten und exportieren in den scraped_data Orner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b542e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_trends(output_dir, num_videos):\n",
    "    try:\n",
    "        # Warte, bis die Video-Elemente geladen sind\n",
    "        WebDriverWait(driver, 15).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'ytd-video-renderer'))\n",
    "        )\n",
    "\n",
    "        # Finde alle Video-Elemente\n",
    "        video_elements = driver.find_elements(By.CSS_SELECTOR, 'ytd-video-renderer')[:num_videos] \n",
    "\n",
    "        video_links = []\n",
    "        for video_element in video_elements:\n",
    "            video_link = video_element.find_element(By.ID, 'video-title').get_attribute('href')\n",
    "            video_links.append(video_link)\n",
    "\n",
    "        #Scrape jedes Video nacheinander. Angefangen mit Platz 1 der Trends\n",
    "        all_videos = []\n",
    "        for rank, video_link in tqdm(enumerate(video_links, start=1), total=len(video_links), desc=\"Scraping Videos\"):\n",
    "            try: \n",
    "                driver.get(video_link)\n",
    "                video_data = scrape_video_data(driver, rank, video_link)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f'Error scraping data for {video_link}: {str(e)}') \n",
    "\n",
    "            if video_data:\n",
    "                tqdm.write\n",
    "                all_videos.append(video_data)\n",
    "\n",
    "        # Daten speichern, einschließlich des aktuellen Zeitstempels\n",
    "        save_videos_with_timestamp(all_videos, output_dir)\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaadd88",
   "metadata": {},
   "source": [
    "Starten des Scrapens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0af0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'scraped_data'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# legt fest bis welchen Platz der Trends gescraped werden soll(startet ab #1)\n",
    "num_videos = 20\n",
    "\n",
    "scrape_trends(output_dir, num_videos)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
